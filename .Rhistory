lines(ascissa,yhat.locreg,col="red",lwd=3)
#MSE:
yhat.locreg.test = predict(fit.locreg,newdata = data.frame(x=xtest))$y
#MSE:
yhat.locreg.test = predict(fit.locreg,newdata = data.frame(x=xtest))
MSE.locreg = mean((yhat.locreg.test - ytest)^2)
MSE.locreg
#MODEL:
fit.ss = smooth.spline(x,y,cv=T)
#cv choiche of lambda
yhat.ss = predict(fit.ss,newdata = data.frame(x=ascissa))
#PLOT
plot(x,y,lwd=2)
lines(ascissa,yhat.ss,col="red",lwd=3)
#MSE:
yhat.ss.test = predict(fit.ss,newdata = data.frame(x=xtest))$y
MSE.ss = mean((yhat.ss.test - ytest)^2)
MSE.ss
#MODEL:
fit.locreg = loess(y ~ x, span = 0.3)
#PLOT:
yhat.locreg = predict(fit.locreg,newdata = data.frame(x=ascissa))
plot(x,y,lwd=2)
lines(ascissa,yhat.locreg,col="red",lwd=3)
#cv choiche of lambda
yhat.ss = predict(fit.ss,newdata = data.frame(x=ascissa))$y
#PLOT
plot(x,y,lwd=2)
lines(ascissa,yhat.ss,col="red",lwd=3)
predict(fit.ss,newdata = data.frame(x=ascissa))$
y
MSE.step
MSE.bs
MSE.ns
MSE.ss
MSE.locreg
MSE.poly
MSE.poly
MSE.step
MSE.bs
MSE.ns
MSE.ss
MSE.locreg
cls
cls()
MSE.poly
MSE.step
MSE.bs
MSE.ns
MSE.ss
MSE.locreg
library(ISLR)
#MODEL:
head(wage)
#MODEL:
head(Wage)
Wage
boxplot(Wage$wage,Wage$year)
boxplot(Wage$wage ~ Wage$year)
plot(Wage$wage ~ Wage$year)
boxplot(Wage$wage ~ Wage$maritl)
boxplot(Wage$wage ~ Wage$rece)
boxplot(Wage$wage ~ Wage$race)
boxplot(Wage$wage ~ Wage$education)
layout(2,2)
boxplot(Wage$wage ~ Wage$year)
boxplot(Wage$wage ~ Wage$maritl)
boxplot(Wage$wage ~ Wage$race)
boxplot(Wage$wage ~ Wage$education)
layout(matrix(c(2,2))
boxplot(Wage$wage ~ Wage$maritl)
boxplot(Wage$wage ~ Wage$race)
boxplot(Wage$wage ~ Wage$education)
gam1 = lm(wage ~ year+ ns(age,5)+ maritl+ race+ eucation+ jobclass+ health+ health_ins,
data = Wage)
summary(gam1)
gam1 = lm(wage ~ year+ ns(age,5)+ maritl+ race+ education+ jobclass+ health+ health_ins,
data = Wage)
summary(gam1)
gam1 = gam(wage ~ year+ ns(age,5)+ maritl+ race+ education+ jobclass+ health+ health_ins,
data = Wage)
summary(gam1)
#PLOT:
layout(matrix(1,8,nrow = 2))
plot.Gam(gam1,se=T,col"red")
plot.Gam(gam1,se=T,co="red")
library(gam)
install.packages("gam")
library(gam)
plot.Gam(gam1,se=T,co="red")
plot.Gam(gam1,se=T,col="red")
#PLOT:
layout(matrix(1,8,nrow = 2))
plot.Gam(gam1,se=T,col="red")
k=10
n = dim(Wage)[1]
df.explore = 1:20
cv.errors = matrix(k,length(df.explore))
set.seed(12345)
folds = sample(1:k,size = n, replace = T)
table(folds)
for (d in df.explore) {
for (i in 1:k) {
#model
gam.i = gam(wage ~ year+ ns(age,d)+ maritl+ race+ education+ jobclass+ health+ health_ins,
data = Wage[folds != i,])
#prediction
predicted = predict(gam.i, Wage[folds == i,])
#MSE
cv.errors[i,d] = sum((predicted - Wage$wage[folds==i])^2)
}
}
mean.cv.errors = apply(cv.errors, 2, mean)
mean.cv.errors = apply(cv.errors, 2, sd)
for (d in df.explore) {
for (i in 1:k) {
#model
gam.i = gam(wage ~ year+ ns(age,d)+ maritl+ race+ education+ jobclass+ health+ health_ins,
data = Wage[folds != i,])
#prediction
predicted = predict(gam.i, Wage[folds == i,])
#MSE
cv.errors[i,d] = sum((predicted - Wage$wage[folds==i,])^2)
}
}
mean.cv.errors = apply(cv.errors, 2, mean)
mean.cv.errors = apply(cv.errors, 2, sd)
plot(df.explore,mean.cv.errors,type = "b",lwd=5)
#suggest 2-5 df
mean.cv.errors = apply(cv.errors, 2, mean)
sd.cv.errors = apply(cv.errors, 2, sd)
plot(df.explore,mean.cv.errors,type = "b",lwd=5)
#suggest 2-5 df
boxplot(cv.errors)
k=10
n = dim(Wage)[1]
df.explore = 1:20
cv.errors = matrix(nrow = k,ncol = length(df.explore))
set.seed(12345)
folds = sample(1:k,size = n, replace = T)
table(folds)
for (d in df.explore) {
for (i in 1:k) {
#model
gam.i = gam(wage ~ year+ ns(age,d)+ maritl+ race+ education+ jobclass+ health+ health_ins,
data = Wage[folds != i,])
#prediction
predicted = predict(gam.i, Wage[folds == i,])
#MSE
cv.errors[i,d] = sum((predicted - Wage$wage[folds==i,])^2)
}
}
mean.cv.errors = apply(cv.errors, 2, mean)
sd.cv.errors = apply(cv.errors, 2, sd)
plot(df.explore,mean.cv.errors,type = "b",lwd=5)
#suggest 2-5 df
boxplot(cv.errors)
# too variable
k=10
n = dim(Wage)[1]
df.explore = 1:20
cv.errors = matrix(0,nrow = k,ncol = length(df.explore))
set.seed(12345)
folds = sample(1:k,size = n, replace = T)
table(folds)
for (d in df.explore) {
for (i in 1:k) {
#model
gam.i = gam(wage ~ year+ ns(age,d)+ maritl+ race+ education+ jobclass+ health+ health_ins,
data = Wage[folds != i,])
#prediction
predicted = predict(gam.i, Wage[folds == i,])
#MSE
cv.errors[i,d] = sum((predicted - Wage$wage[folds==i,])^2)
}
}
mean.cv.errors = apply(cv.errors, 2, mean)
sd.cv.errors = apply(cv.errors, 2, sd)
plot(df.explore,mean.cv.errors,type = "b",lwd=5)
#suggest 2-5 df
boxplot(cv.errors)
# too variable
k=10
n = dim(Wage)[1]
df.explore = 1:20
cv.errors = matrix(nrow = k,ncol = length(df.explore))
set.seed(12345)
folds = sample(1:k,size = n, replace = T)
table(folds)
for (d in df.explore) {
for (i in 1:k) {
#model
gam.i = gam(wage ~ year+ ns(age,d)+ maritl+ race+ education+ jobclass+ health+ health_ins,
data = Wage[folds != i,])
#prediction
predicted = predict(gam.i, Wage[folds == i,])
#MSE
cv.errors[i,d] = sum((predicted - Wage$wage[folds==i,])^2)
}
}
mean.cv.errors = apply(cv.errors, 2, mean)
sd.cv.errors = apply(cv.errors, 2, sd)
plot(df.explore,mean.cv.errors,type = "b",lwd=5)
#suggest 2-5 df
boxplot(cv.errors)
# too variable
k=10
n = dim(Wage)[1]
df.explore = 1:20
cv.errors = matrix(nrow = k,ncol = length(df.explore))
set.seed(12345)
folds = sample(1:k,size = n, replace = T)
table(folds)
for (d in df.explore) {
for (i in 1:k) {
#model
gam.i = gam(wage ~ year+ ns(age,d)+ maritl+ race+ education+ jobclass+ health+ health_ins,
data = Wage[folds != i,])
#prediction
predicted = predict(gam.i, Wage[folds == i,])
#MSE
cv.errors[i,d] = sum((predicted - Wage$wage[folds==i])^2)
}
}
mean.cv.errors = apply(cv.errors, 2, mean)
sd.cv.errors = apply(cv.errors, 2, sd)
plot(df.explore,mean.cv.errors,type = "b",lwd=5)
#suggest 2-5 df
boxplot(cv.errors)
# too variable
layout(1)
plot(df.explore,mean.cv.errors,type = "b",lwd=5)
boxplot(cv.errors)
table(Wage$year)
k=10
n = dim(Wage)[1]
df.explore = 1:7
cv.errors = matrix(nrow = k,ncol = length(df.explore))
set.seed(12345)
folds = sample(1:k,size = n, replace = T)
table(folds)
for (d in df.explore) {
for (i in 1:k) {
#model
gam.i = gam(wage ~ ns(year,i) + ns(age,5)+ maritl+race+education+jobclass+health+ health_ins,
data = Wage[folds != i,])
#prediction
predicted = predict(gam.i, Wage[folds == i,])
#MSE
cv.errors[i,d] = sum((predicted - Wage$wage[folds==i])^2)
}
}
mean.cv.errors = apply(cv.errors, 2, mean)
sd.cv.errors = apply(cv.errors, 2, sd)
#PLOT:
layout(1)
plot(df.explore,mean.cv.errors,type = "b",lwd=5)
#suggest 2 or 5 dfs
boxplot(cv.errors)
# too variable, try various df.explore length
gam.ss = gam(wage ~ year + s(age, spar = exp(-1))+ maritl+race+education+jobclass+health+ health_ins,data = Wage)
gam.ss
gam.final = gam(wage ~ ns(year,1) + ns(age,5)+
maritl+race+education+jobclass+health+ health_ins,
data = Wage)
gam.ss = gam(wage ~ year + s(age, spar = exp(-1)) + maritl+race+education+jobclass+health+ health_ins,
data = Wage)
plot.Gam(gam.ss)
gam.ss = gam(wage ~ year + s(age, spar = exp(-1)) +
maritl+race+education+jobclass+health+health_ins,
data = Wage)
#NB: lambda parameter is spar
gam.ss
plot.Gam(gam.ss)
library(tree)
install.packages("tree")
library(tree)
tree.credit = tree(Balance ~ ., data = Credit[,-1])
tree.credit
#PLOT:
plot(tree.credit,lwd=2)
text(tree.credit,digits = 3,cex=0.5)
text(tree.credit,digits = 3,cex=0.6)
plot(tree.credit,lwd=2)
text(tree.credit,digits = 3,cex=0.6)
contr = tree.control(nobs = dim(Credit)[1],
mincut = 1,
mindev = 0.0001)
tree.credit.big = tree(Balance ~ .,
data = Credit[,-1],
control = contr)
tree.credit
plot(tree.credit,lwd=2)
text(tree.credit,digits = 3,cex=0.6)
plot(tree.credit.big,lwd=2)
text(tree.credit,digits = 3,cex=0.3)
text(tree.credit.big,digits = 3,cex=0.3)
text(tree.credit.big,digits = 3,cex=0.5)
plot(tree.credit.big,lwd=2)
text(tree.credit.big,digits = 3,cex=0.5)
#find optimal tree with CV
cv.credit = cv.tree(tree.credit.big, FUN = prune.tree())
#find optimal tree with CV
cv.credit = cv.tree(tree.credit.big, FUN = prune.tree())
#find optimal tree with CV
cv.credit = cv.tree(tree.credit.big, FUN = prune.tree)
plot(cv.credit$size,cv.credit$dev)
plot(cv.credit$size,cv.credit$dev,
xlab="size of subtrees",ylab = "CV error")
#we see a substatial decrese starting from 12/13
cbind(cv.credit$size,cv.credit$dev)
#BEST TREE ESTIMATION
prune.credit = prune.tree(tree.credit.big, best = 12)
plot(prune.credit,lwd)
text(prune.credit,digits = 3,cex=0.6)
#PLOT:
plot(prune.credit,lwd=2)
text(prune.credit,digits = 3,cex=0.6)
text(prune.credit,digits = 4,cex=0.6)
#PLOT:
plot(prune.credit,lwd=2)
text(prune.credit,digits = 4,cex=0.6)
hist(Carseats)
hist(Carseats$Sales)
#create a fake categorical variable
high = ifelse(Carseats$Sales <= 8, "no","yes")
high = factor(high)
table(high)
#new dataset
Carseats = data.frame(Carseats,high)
#MODEL:
tree.carseat = tree(high~.,
data = Carseats,
method = "Gini")
plot(tree.carseat)
#MODEL:
tree.carseat = tree(high ~ .,
data = Carseats[,-1],
method = "Gini")
plot(tree.carseat)
text(tree.carsea)
text(tree.carseat)
text(tree.carseat,cex=0.1)
plot(tree.carseat)
text(tree.carseat,cex=0.1)
text(tree.carseat,cex=0.3)
text(tree.carseat,cex=0.5)
plot(tree.carseat)
text(tree.carseat,cex=0.5)
contrasts(Carseats$ShelveLoc)
summary(tree.carseat)
tree.carseat
#PRUNING:
cv.carseat = cv.tree(tree.carseat,prune.misclass)
#PRUNING:
cv.carseat = cv.tree(tree.carseat,FUN = prune.misclass)
plot(cv.carseat$size,cv.carseat$dev)
plot(cv.carseat$size,cv.carseat$dev,type = "b")
plot(cv.carseat$size,cv.carseat$dev,type = "b")
#PRUNING:
cv.carseat = cv.tree(tree.carseat,FUN = prune.misclass)
plot(cv.carseat$size,cv.carseat$dev,type = "b")
cv.carseat = cv.tree(tree.carseat,FUN = prune.misclass, k=400)
plot(cv.carseat$size,cv.carseat$dev,type = "b")
cv.carseat = cv.tree(tree.carseat,FUN = prune.misclass,K = dim(Carseats)[1])
plot(cv.carseat$size,cv.carseat$dev,type = "b")
#BEST MODEL:
prune.carseat = prune.misclass(tree.carseat,best = 5)
plot(prune.carseat)
plot(prune.carseat); text(prune.carseat,cex=0.5)
plot(prune.carseat); text(prune.carseat)
library(MASS)
head(Boston)
train = sample(n, 3)
train = sample(n, 300)
install.packages("randomForest")
#MODEL:
library(randomForest)
bag.boston = randomForest(medv ~ .,
data = Boston,
subset = train,
mtry = dim(Boston)[2]-1) #number of predictors (all)
bag.boston = randomForest(medv ~ .,
data = Boston,
subset = train,
mtry = dim(Boston)[2]-1,
importance = T,
ntree = 1000) #number of predictors (all)
#OOB error
bag.boston$mse
bag.boston = randomForest(medv ~ .,
data = Boston,
subset = train,
ntry = dim(Boston)[2]-1,
importance = T,
ntree = 1000) #number of predictors (all)
#OOB error
bag.boston$mse
bag.boston = randomForest(medv ~.,
data = Boston,
subset = train,
mtry = dim(Boston)[2]-1,
importance = T,
ntree = 1000) #number of predictors (all)
library(installr)
install.packages("installr")
library(installr)
updateR()
cat("result:",3+4,"\n")
cat("result:",3+4)
print(i)
for i in 1:15{
print(i)
}
for i in 1:15{
print(i)
}
for i in c(1:15){
print(i)
}
print(i)
for(i in c(1:15) ){
print(i)
}
list.files()
library(zoo)
setwd("C:/Users/ferro/Desktop/R/MICE")
renv::activate()
# DATASET
df_miss = airquality
airquality$Ozone
summary(airquality$Ozone)
scale(airquality$Ozone)
summary(scale(airquality$Ozone))
##### KNN  ####
?scale
# 1: normalize variables
function(normalize){(x-min(x) / max(x)-min(x))}
{(x-min(x) / max(x)-min(x))}
# 1: normalize variables
normalize = function(x){(x-min(x) / max(x)-min(x))}
df_median = data.frame(
apply(df_miss, 2, FUN = normalize())
)
df_median = data.frame(
apply(df_miss, 2, FUN = normalize())
)
# 1: normalize variables
normalize = function(x){
(x-min(x)) / (max(x)-min(x))
}
df_median = data.frame(
apply(df_miss, 2, FUN = normalize())
)
apply(df_miss, 2, FUN = normalize
df_median = data.frame(
apply(df_miss, 2, FUN = normalize)
)
df_median = data.frame(
apply(df_miss, 2, FUN = normalize)
)
summary(df_median$Ozone)
normalize = function(vec){
not_na = vec[!is.na(vec)]
(not_na - min(not_na)) / (max(not_na) - min(not_na))
}
df_norm = data.frame(
apply(df_miss, 2, FUN = normalize)
)
normalize = function(x){
(x - min(x)) / (max(x) - min(x))
}
df_norm = data.frame(
apply(df_miss, 2, FUN = normalize)
)
View(df_norm)
library(class)
normalize = function(x){
out = (x - min(x)) / (max(x) - min(x))
return(out)
}
df_norm = data.frame(
apply(df_miss, 2, FUN = normalize)
)
View(df_norm)
normalize = function(x){
out = (x - min(x,na.rm = T)) / (max(x,na.rm = T) - min(x,na.rm = T))
return(out)
}
df_norm = data.frame(
apply(df_miss, 2, FUN = normalize)
)
View(df_norm)
n = nrow(df_norm)
train_obs = sample( 1:n, size = 0.2*n)
df_train = df_norm[train_obs,]
df_test = df_norm[-train_obs,]
airquality
# DATASET
df_miss = iris
class_rule = knn(df_train, df_test,
cl = df_miss$Species)
View(df_miss)
library(DMwR)
install.packages("DMwR")
getOption("defaultPackages")
ownames(installed.packages(priority = "base"))
rownames(installed.packages(priority = "base"))
library("VIM")
library(VIM)
install.packages("VIM")
library(mice)
